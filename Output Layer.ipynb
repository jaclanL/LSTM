{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At time step t, given the measurement signal   tau_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3;\n",
    "n_out = 2;\n",
    "n_res = 100; #size reservoir\n",
    "s = np.zeros((n,1))               # From self-organized layer\n",
    "r = np.zeros((n_res,1))           # From Reservoir\n",
    "W_out = np.zeros((n_out,n_res))\n",
    "W_dir = np.zeros((n_out,n))\n",
    "W_train = np.hstack((W_out, W_dir)) # Size n_out x (n_res + n)\n",
    "tau = 0;\n",
    "c_t = np.hstack((r.T,s.T)).T # Size (n_res + n) x 1\n",
    "\n",
    "\n",
    "# Inputs\n",
    "sigma_2 = 0.01;\n",
    "phi_2 = 1; #random number for now\n",
    "\n",
    "#Initialize \n",
    "V_0 = np.zeros((n_res+n, n_res+n, n_out)) # size     (n_res+n) x (n_res+n) x (n_out)\n",
    "for i in range(n_out):\n",
    "    V_0[:,:,i] = phi_2 * np.eye(n_res + n)\n",
    "\n",
    "# tau_t received from the sensor\n",
    "tau_t = 5\n",
    "    \n",
    "# From t = 1\n",
    "    \n",
    "# Computation of c_t+1\n",
    "# For t+1\n",
    "c_dot = np.hstack((r.T,s.T)).T # Size (n_res + n) x 1\n",
    "o_dot = np.dot(W_train,c_dot)\n",
    "\n",
    "#Update the weights\n",
    "V_dot = np.zeros((n_res+n, n_res+n, n_out))\n",
    "#Update V\n",
    "for i in range(n_out):\n",
    "    V_dot[:,:,i] = np.linalg.inv(V_0[:,:,i] + (1/sigma_2)* c_t @ c_t.T)\n",
    "\n",
    "W_train_dot = np.zeros(np.shape(W_train))\n",
    "for i in range(n_out):\n",
    "    a = V_dot[:,:,i] @ np.linalg.inv(V_0[:,:,i]) @ W_train[i,:].T\n",
    "    b = (1/sigma_2) * V_dot[:,:,i] @ c_dot * tau\n",
    "    temp = np.sum([a.T, b.T], axis=0)\n",
    "    W_train_dot[i,:] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to implement with the rest of the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that we create an overall class \"Neural Network\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class output_layer:\n",
    "    def __init__(self, s_size, r_size, n_ouput, sigma_2 = 0.1, phi_2 = 1):\n",
    "        \n",
    "        self.s_size = s_size   # Input from self-organized layer\n",
    "        self.r_size = r_size   # Input from Reservoir\n",
    "        self.o_size = o_size\n",
    "        self.n_ouput = n_ouput\n",
    "        self.sigma_2 = sigma_2\n",
    "        self.phi_2 = phi_2\n",
    "        #self.tau = tau_sens # Torque measurements\n",
    "        \n",
    "    def initweights(self):\n",
    "        W_out = np.random.random((self.n_ouput,self.r_size))\n",
    "        W_dir = np.random.random((self.n_ouput,self.s_size))\n",
    "        #Normalise W_out, W_dir\n",
    "        W_outmax, W_outmin = W_out.max(), W_out.min()\n",
    "        W_dirmax, W_dirmin = W_dir.max(), W_dir.min()\n",
    "        self.W_out = (W_out - W_outmin)/(W_outmax - W_outmin)\n",
    "        self.W_dir = (W_dir - W_dirmin)/(W_dirmax - W_dirmin)\n",
    "        self.W_train = np.hstack((W_out, W_dir))\n",
    "        \n",
    "        #Initialize V\n",
    "        self.V = self.phi_2 * np.identity((self.r_size + self.s_size, self.r_size + self.s_size, self.n_ouput))\n",
    "        \n",
    "    def update_parameters(self, c_t, tau, W_train):\n",
    "        #Update V\n",
    "        V_cache = self.V\n",
    "        for i in range(n_out):\n",
    "            self.V[:,:,i] = np.linalg.inv(self.V[:,:,i] + (1/self.sigma_2)* c_t @ c_t.T)\n",
    "        #Update W_train\n",
    "        for i in range(n_out):\n",
    "            a = self.V[:,:,i] @ np.linalg.inv(V_cache[:,:,i]) @ W_train[i,:].T\n",
    "            b = (1/sigma_2) * V_dot[:,:,i] @ c_dot * tau\n",
    "            self.W_train[i,:] = np.sum([a.T, b.T], axis=0)\n",
    "            \n",
    "    def _update(c_dot):\n",
    "        o_dot = np.dot(self.W_train, c_dot)\n",
    "        return o_dot\n",
    "        \n",
    "    def fit(self, self_input, res_input, tau_sens, outputs, epoch):    #TRAINING\n",
    "        \"\"\"\n",
    "        Collect the network's reaction to training data, train readout weights.\n",
    "\n",
    "        Args:\n",
    "            inputs: array of dimensions (n_res + n_self) x N_training_samples\n",
    "            outputs: array of dimension n_outputs x N_training_samples\n",
    "\n",
    "        Returns:\n",
    "            the network's output on the training data, using the trained weights\n",
    "        \"\"\"\n",
    "        # Maybe it's needed to add some reshape in order to adapt the input data to the code\n",
    "        \n",
    "        c = np.hstack((self_input.T,res_input.T)).T # Size (n_res + n_self) x N_training_samples\n",
    "        for n in range(1, c.shape[1]):\n",
    "            output[n, :] = self._update(c[:,n])\n",
    "            #Update the weights when given torque measurement\n",
    "            if n!=1:\n",
    "                update_parameters(self, c[:,n-1], self.tau[n], self.W_train)\n",
    "            else:\n",
    "                update_parameters(self, c_t, self.tau[n], np.zeros(W_train.shape))\n",
    "                    \n",
    "    def predict(self, self_input, res_input):\n",
    "        \"\"\"\n",
    "        Apply the learned weights to the network's reactions to new input.\n",
    "\n",
    "        Args:\n",
    "            inputs: array of dimensions (N_test_samples x n_inputs)\n",
    "            continuation: if True, start the network from the last training state\n",
    "\n",
    "        Returns:\n",
    "            Array of output activations\n",
    "        \"\"\"\n",
    "        c = np.hstack((self_input.T,res_input.T)).T\n",
    "        return self._update(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "n_self = 10\n",
    "n_res = 10\n",
    "n_out = 3\n",
    "train_self_inputs = np.random.random((n_self,n_samples))\n",
    "train_res_inputs = np.random.random((n_res,n_samples))\n",
    "tau_sens = 1;\n",
    "train_output = np.random.random((n_out,n_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer = output_layer(s_size = 10,\n",
    "                            r_size = 10,\n",
    "                            n_ouput = 3,\n",
    "                            sigma_2 = 0.1,\n",
    "                            phi_2 = 1)\n",
    "\n",
    "pred_train = output_layer.fit(train_self_inputs,train_res_inputs, tau_sens, train_output)\n",
    "print(\"test error:\")\n",
    "pred_test = esn.predict(test_self_inputs,test_res_inputs)\n",
    "print(np.sqrt(np.mean((pred_test - test_output)**2)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
