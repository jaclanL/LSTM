{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Components Echo State Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.sparse import rand as sprand\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import eigs as speigs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCESN():\n",
    "    def __init__(self,nInputUnits,nReservoirUnits,nOutputUnits,spectralRadius,sigma2=0.1, phi2 = 1,eta):\n",
    "        print('Creating PC-ESN...')\n",
    "        ### STRUCTURE\n",
    "        self.nInputUnits = nInputUnits\n",
    "        self.nReservoirUnits = nReservoirUnits\n",
    "        self.nOutputUnits = nOutputUnits\n",
    "        \n",
    "        self.sigma2 = sigma2\n",
    "        self.phi2 = phi2\n",
    "        self.eta = eta # learning rate\n",
    "        \n",
    "        # initalize input sum and mean\n",
    "        self.inputMean = 0 \n",
    "        self.inputAbs = 0.00001\n",
    "        self.i = 0\n",
    "\n",
    "        ### INITIALIZE WEIGHTS JAEGER (Sparse reservoir weights) (Polydoros et. al. Algorithm 1)\n",
    "        success = 0                                             \n",
    "        while success == 0: # following block might fail\n",
    "            try:\n",
    "                self.Wres = sprand(nReservoirUnits, nReservoirUnits, density=10/nReservoirUnits)\n",
    "                self.Wres = self.Wres.toarray()\n",
    "                self.Wres[self.Wres!=0] -= 0.5 # modify only nonzero elements\n",
    "                self.Wres = csr_matrix(self.Wres) # back to sparse\n",
    "                maxVal = max(abs(speigs(A=self.Wres, k=1, which='LM')[0]))\n",
    "                self.Wres /= maxVal\n",
    "                success = 1\n",
    "            except:\n",
    "                success = 0   \n",
    "        self.Wres *= self.spectralRadius\n",
    "        \n",
    "        self.Win = eye(nInputUnits)\n",
    "        self.Wself = (2.0*random.rand(nReservoirUnits, nInputUnits)-1.0) # init not mentioned???\n",
    "        self.Wfb = (2.0 * random.rand(nReservoirUnits, nOutputUnits)- 1.0)\n",
    "        self.Wout = (2.0 * random.rand(nOutputUnits,nReservoirUnits)- 1.0) # init not mentioned???\n",
    "        self.Wdir = (2.0 * random.rand(nOutputUnits,nInputUnits)- 1.0)\n",
    "        \n",
    "        self.Wtrain = zeros((nOutputUnits, nInputUnits + nReservoirUnits))\n",
    "\n",
    "        self.V = self.sigma2 * eye(nInputUnits + nReservoirUnits)\n",
    "        \n",
    "        print('Successful!')\n",
    "        \n",
    "        def train(self, inputSample,targetSample):\n",
    "            # Normalize and center input\n",
    "            self.inputMean = self.inputMean + (inputSample-self.inputMean)/(self.i+1)\n",
    "            inputSample -= self.inputMean\n",
    "            self.inputAbs = maximum(self.inputAbs, absolute(inputSample))\n",
    "            inputSample /= self.inputAbs\n",
    "            self.i += 1 # update index\n",
    "\n",
    "            self.s = tanh(self.Win @ inputSample) # update self-organized layer\n",
    "            self.r = tanh(self.Wres @ self.r + self.Wself @ self.s + self.Wfb @ self.o)\n",
    "            self.o = self.Wtrain @ self.ct\n",
    "            \n",
    "            Vprev = self.V\n",
    "            self.V = linalg.inv(linalg.inv(Vprev) + (1/self.sigma_2) * c @ c.T)\n",
    "            \n",
    "            a = self.V @ np.linalg.inv(V_prev) @ self.W_train.T\n",
    "            b = 1/self.sigma_2 * self.V @ c_t @ tau.T\n",
    "            \n",
    "            self.Wtrain = np.sum([a.T, b.T], axis=0)\n",
    "        \n",
    "            # Calculate GHL update \n",
    "            triang = tril(self.s @ self.s.T)\n",
    "            dWin = self.eta*(self.s@inputSample.T - triang @ self.Win)\n",
    "\n",
    "            self.Win += dWin # update Win matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useless(?) stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init\n",
    "self.noiseLevel = 0.0\n",
    "self.leakingRate = 1\n",
    "self.forgetPoints = 100\n",
    "self.reg = 1e-5 # If ridge regression!!! (something else than 1)\n",
    "\n",
    "self.RLS_lambda = 0.9999995\n",
    "self.RLS_delta = 0.000001\n",
    "\n",
    "self.trained = 0\n",
    "self.pseudo = True\n",
    "\n",
    "# init default\n",
    "self.inputScaling = ones((nInputUnits, 1)) # MAKE SURE INPUT IS NORMALIZED!!!\n",
    "self.inputShift = zeros((nInputUnits, 1))\n",
    "self.teacherScaling = ones((nOutputUnits, 1)) # DOES TEACHER SCALING MAKE ANY DIFFERENCE???\n",
    "self.teacherShift = zeros((nOutputUnits, 1))\n",
    "self.teacherForcing = True # Desired output y_teacher instead of predicted y -> Ridge regression!!!  \n",
    "self.feedbackScaling = zeros((nOutputUnits, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
