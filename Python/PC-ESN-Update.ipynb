{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.sparse import rand as sprand\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import eigs as speigs\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_input(inputSequence):\n",
    "    iMu = mean(inputSequence, axis=0)\n",
    "    iMax = amax(abs(inputSequence), axis=0)\n",
    "    normInputSequence = (inputSequence-iMu)/iMax\n",
    "    return normInputSequence\n",
    "\n",
    "def normalized_mse(pred, true):\n",
    "    # true (nSamples x nJoints)\n",
    "    # pred (nSamples x nJoints)\n",
    "    #return error_joints, error_avg\n",
    "    \n",
    "    # Normalizing with variance\n",
    "    nSamples = size(true,axis=0);\n",
    "    sigma = var(true,axis=0);\n",
    "    \n",
    "    # Calculating each error value\n",
    "    es = abs(true-pred)**2\n",
    "    s = sum(es,axis=0)\n",
    "    error_joints = s/(nSamples*sigma) # Mean error of each joint\n",
    "    error_avg = mean(error_joints,axis=0); # Combined joint error\n",
    "    \n",
    "    return error_joints, error_avg\n",
    "\n",
    "#maxInput = array([]) # Fill with max (reasonable) ALSO ADD TO INIT IF USING!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PC-ESN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCESN():\n",
    "    def __init__(self,nInputUnits,nReservoirUnits,nOutputUnits,spectralRadius,sigma2,phi2,smoothFactor):\n",
    "        print('Generating PC-ESN...')\n",
    "        # Structure\n",
    "        self.nInputUnits = nInputUnits\n",
    "        self.nReservoirUnits = nReservoirUnits\n",
    "        self.nOutputUnits = nOutputUnits\n",
    "        \n",
    "        # Parameters\n",
    "        self.spectralRadius = spectralRadius # 0<sR<1 to ensure ESP! default 0.4???\n",
    "        self.sigma2 = sigma2\n",
    "        self.phi2 = phi2\n",
    "        self.eta = 1 # learning rate,  0.1 -> 0.01 eta^p < inf, sum(eta) = inf, \n",
    "        \n",
    "        # Initalize input sum and mean variables\n",
    "        self.inputMean = zeros((nInputUnits,1))\n",
    "        #self.maxTorque = maxTorque\n",
    "        self.t = 0\n",
    "\n",
    "        # Initialize weights, H.Jaeger (Sparse reservoir weights)\n",
    "        success = 0                                             \n",
    "        while success == 0: # following block might fail\n",
    "            try:\n",
    "                self.Wres = sprand(nReservoirUnits, nReservoirUnits, density=10/nReservoirUnits)\n",
    "                self.Wres = self.Wres.toarray()\n",
    "                self.Wres[self.Wres!=0] -= 0.5 # modify only nonzero elements\n",
    "                self.Wres = csr_matrix(self.Wres) # back to sparse\n",
    "                maxVal = max(abs(speigs(A=self.Wres, k=1, which='LM')[0]))\n",
    "                self.Wres /= maxVal\n",
    "                success = 1\n",
    "            except:\n",
    "                success = 0   \n",
    "        self.Wres *= self.spectralRadius\n",
    "        \n",
    "        self.Win = eye(nInputUnits)\n",
    "        self.Wself = (2.0*random.rand(nReservoirUnits, nInputUnits)-1.0) # init not mentioned???\n",
    "        self.Wfb = (2.0 * random.rand(nReservoirUnits, nOutputUnits)- 1.0)\n",
    "        self.Wout = zeros((nOutputUnits,nReservoirUnits))\n",
    "        self.Wdir = zeros((nOutputUnits,nInputUnits))\n",
    "        self.Wtrain = hstack((self.Wout,self.Wdir)) # just a combination of [Wout Wdir]\n",
    "        \n",
    "        self.r = zeros((nReservoirUnits,1))\n",
    "        self.s = zeros((nInputUnits,1))\n",
    "        self.o = zeros((nOutputUnits,1))\n",
    "        self.c = vstack((self.r, self.s))\n",
    "        \n",
    "        self.smoothFactor = smoothFactor # If ~1 trust new data, if ~0 rely on previous data\n",
    "        \n",
    "        #self.outputMean = zeros((nOutputUnits,1))\n",
    "        #self.M2 = zeros((nOutputUnits,1))\n",
    "\n",
    "        # Initialize covariance matrix\n",
    "        self.V = self.phi2 * eye(nInputUnits + nReservoirUnits)\n",
    "        \n",
    "        print('Successful!\\n')\n",
    "        \n",
    "    def train(self, inputSample,targetSample):\n",
    "        \"\"\"Training network on inputs with additional help of target values.\n",
    "\n",
    "        Args:\n",
    "            inputSample: numpy array (inputs x 1)\n",
    "            targetSample: numpy array (inputs x 1)\n",
    "        Returns:\n",
    "            Updated parameters (weights and states)\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # Center input\n",
    "        self.inputMean = self.inputMean + (inputSample-self.inputMean)/(self.t+1)\n",
    "        inputSample -= self.inputMean\n",
    "        \n",
    "        # Normalize with pre-determined max values (NOT PART OF ALGORITHM):\n",
    "        #inputSample /= self.maxInput\n",
    "        \n",
    "        self.t += 1 # update time index\n",
    "\n",
    "        self.s = tanh(self.Win @ inputSample) # update self-organized layer\n",
    "        self.r = tanh(self.Wres @ self.r + self.Wself @ self.s + self.Wfb @ self.o)\n",
    "        ccurr = self.c\n",
    "        self.c = vstack((self.r, self.s))\n",
    "        self.o = self.Wtrain @ self.c\n",
    "        \n",
    "        # Simple smoothing (NOT PART OF ALGORITHM)\n",
    "        oldOut = self.o\n",
    "        self.o = (1-self.smoothFactor)*oldOut + self.smoothFactor*(self.Wtrain @ self.c)\n",
    "\n",
    "        Vprev = self.V\n",
    "        self.V = linalg.inv(linalg.inv(Vprev) + (1/self.sigma2) * ccurr @ ccurr.T)\n",
    "        a = self.V @ linalg.inv(Vprev) @ self.Wtrain.T\n",
    "        b = 1/self.sigma2 * (self.V @ ccurr) @ targetSample.T\n",
    "        \n",
    "        #self.Wtrain = sum([a.T, b.T], axis=0)\n",
    "        self.Wtrain = a.T + b.T\n",
    "\n",
    "        # Calculate GHL update \n",
    "        dWin = self.eta*(inputSample@self.s.T - tril(self.s @ self.s.T) @ self.Win)\n",
    "        self.Win += dWin # update Win matrix\n",
    "        \n",
    "        # Update learning rate (NOT PART OF ALGORITHM)\n",
    "        self.eta = 1/sqrt(self.t)\n",
    "        \n",
    "        # Welford's Online variance algorithm (NOT PART OF ALGORITHM)\n",
    "        #oldM = self.outputMean;\n",
    "        #delta = targetSample-self.outputMean;\n",
    "        #self.outputMean = self.outputMean + delta/obj.t;\n",
    "        #self.M2 = self.M2 + (targetSample-self.outputMean) * delta;\n",
    "        #self.sigma2 = vstack((ones(self.nReservoirUnits,1),matlib.repmat(self.M2/self.t,(3,1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nInputs = 21\n",
    "nOutputs = 7\n",
    "split = 0.5\n",
    "\n",
    "data = genfromtxt('train_data2.csv', delimiter=',')\n",
    "# 'baxter_rand'\n",
    "# 'sarcos'\n",
    "ind = round(split*data.shape[0])\n",
    "\n",
    "uTrain = data[0:ind,0:nInputs,newaxis]\n",
    "yTrain = data[0:ind,nInputs:,newaxis]\n",
    "uTest = data[ind:,0:nInputs,newaxis]\n",
    "yTest = data[ind:,nInputs:,newaxis]\n",
    "\n",
    "# Normalize input\n",
    "uTrain = normalize_input(uTrain)\n",
    "uTest = normalize_input(uTest)\n",
    "\n",
    "trainSamples = uTrain.shape[1]\n",
    "testSamples = uTest.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nInputUnits = 21\n",
    "nReservoirUnits = 600\n",
    "nOutputUnits = 7\n",
    "spectralRadius = 0.3 # Tune!!!\n",
    "sigma2 = 0.1\n",
    "phi2 = 1\n",
    "smoothFactor = 0.9\n",
    "\n",
    "pcesn = PCESN(nInputUnits,nReservoirUnits,nOutputUnits,spectralRadius,sigma2,phi2,smoothFactor)\n",
    "\n",
    "totalSamples = 3000 # Polydoros model seems to converge in 2000 samples!\n",
    "output = zeros((7,totalSamples,1))\n",
    "\n",
    "for i in trange(totalSamples): # or standard \"range\" to remove progress bar \n",
    "    pcesn.train(uTrain[i,:],yTrain[i,:])\n",
    "    output[:,i] = pcesn.o\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,15))\n",
    "for j in range(1,8):\n",
    "    plt.subplot(420+j)\n",
    "    plt.plot(output[j-1,1500:2000],'b')\n",
    "    plt.plot(yTrain[1500:2000,j-1],'r')\n",
    "    plt.title('Joint {}'.format(j))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_joints, error_avg = normalized_mse(output[:,2700:totalSamples,0].T, yTrain[2700:totalSamples,:,0])\n",
    "print(error_joints)\n",
    "print(error_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_test = zeros((7,testSamples,1))\n",
    "\n",
    "for i in trange(testSamples): # or standard \"range\" to remove progress bar \n",
    "    pcesn.train(uTest[i,:],yTest[i,:])\n",
    "    output_test[:,i] = pcesn.o\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
